{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialogue systems use a variety of mechanisms to carryout informative and coherent conversations withtheir users.   These conversations can be achieved through rule-basd,  template-based, retrieval-based approaches or in a data-driven manner that teaches the agent to learn from raw conversational data. This workshop will focus on the retreival-based method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreival-Based Chatbot\n",
    "A retrieval-based agent or chatbot retrieves related responses from queries in the corpus that are similar to the given query.  We are not interested in generating a new response, but select the most suitable response (originally made to other queries) as reply to the current query. We will be try to do this by having a set of questions with labelled intents and then try to classify the intent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Colab\n",
    "\n",
    "- Sign in to you Google account.\n",
    "- Access the [Colab Welcome Page](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true) and click on ‚ÄòGithub‚Äô. In the ‚ÄòEnter a GitHub URL or search by organization or user‚Äô line enter `https://github.com/bespoke-inc/bespoke-public-talks`. We will be using the notebook in folder `2020/2020-08-22-MLT-Rules-to-DL`\n",
    "- You need to tell Colab that you are interested in using a GPU. You can do this by clicking on the `Runtime` tab and selecting `Change runtime type`. A pop-up window will appear. Select `GPU` from the menu and `Save`.\n",
    "- Install the necessary dependencies by creating a code cell, and running: `!pip install -r requirements.txt.` This will take a few seconds.\n",
    "- Save your work to Google Drive by clicking on ‚ÄòFile‚Äô and then ‚ÄòSave‚Äô and then `SAVE A COPY IN DRIVE.` in the pop-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop Task #1: Create a corpus\n",
    "\n",
    "The first task will be making your own training data based on the above format. We will work a small dataset that we've provided and later some publicly available ones but participants are expected to create their own for this part of the workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "This is a sample format of the training data we want to use:\n",
    "\n",
    "```\n",
    "training_phrases = {\n",
    "    intents : {\n",
    "        'when_is_check_in' : ['when is check-in','When can I check in?','when's checkin'],\n",
    "        'where_is_the_front_desk' : ['Where is the front desk?','what is the location of the front desk?'...]}\n",
    "    answers : {\n",
    "        'when_is_check_in' : 'Check in is at 3pm! :)',\n",
    "        'where_is_the_front_desk' : 'The front desk is located on the 2nd floor.'}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = json.load(open('./sample_data.json','r')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based intent ~~classification~~ matching\n",
    "\n",
    "The simplest approach to find if an query falls into a certain intent is to do some string comparison with our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = \"I don't know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(query):\n",
    "    for i, (intent, phrases) in enumerate(training_data.items()):\n",
    "        if query in phrases:\n",
    "            return intent\n",
    "    return UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.is_there_early_check_in'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(\"is there early check-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(\"when do i checkin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(\"can i check-in earlier than 12pm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial String Matching\n",
    "Instead of checking is the entire query string exists in our dataset, we try to find a partial match\n",
    "and pick the intent that matches most closely. We will try to do this with using Levenshtein Distance \n",
    "to calculate the differences between sequences. The library [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy)\n",
    "can help us do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_matching(query):\n",
    "    for i, (intent, phrases) in enumerate(training_data.items()):\n",
    "        match, score = process.extractOne(query, phrases)\n",
    "        if score > 90:\n",
    "            return intent\n",
    "    return UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.when_is_check_in'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_matching(\"when do i check-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.is_there_early_check_in'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_matching(\"can i check-in earlier than 12pm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.when_is_check_in'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_matching(\"what time is early check-in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Classification\n",
    "We will now add a probabilistic classifier to our set of methods to get better intent classification.\n",
    "The algorithm we will use is [naive bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "Naive Bayes classifiers works quite well for small amount of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "Before we feed it to our model for training we need to tokenize our training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',parse=False,tagger=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'can', 'i', 'check', 'in', '?']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"when can i check in?\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'can', 'i', 'check', '-', 'in', '?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"when can i check-in?\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'did', \"n't\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"i didn't\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank', 'you', '„ÅÇ„Çä„Åå„Å®„ÅÜ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"thank you „ÅÇ„Çä„Åå„Å®„ÅÜ\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did', \"n't\", 'could', \"n't\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"didn't    couldn't   \")\n",
    "[tok.text for tok in doc if tok.text.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_nd_join(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return \" \".join(tok.text for tok in doc if tok.text.strip() not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xs_ys(train_data):\n",
    "    x, y = [], []\n",
    "    for i, (intent, phrases) in enumerate(training_data.items()):\n",
    "        x += [tokenize_nd_join(phrase) for phrase in phrases]\n",
    "        y += [intent]*len(phrases)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y):\n",
    "    vect = CountVectorizer(ngram_range=(1,2),max_features=None)\n",
    "    nb = Pipeline([('vect',vect),('clf',ComplementNB(alpha=1.0,norm=False))])\n",
    "    nb.fit(x,y)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_xs_ys(training_data)\n",
    "nb_model = train(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- CJK\n",
    "- normalize contractions\n",
    "- remove hyphens\n",
    "- remove stopwords\n",
    "- check for typos\n",
    "- normalize plurals\n",
    "- normalize ascii\n",
    "- normalize emojis\n",
    "- remove punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "EMOJIS = [[':)', 'üòÄ'],[';)', 'üòâ'],[':(', 'üòû'],[';((', 'üò¢'],[':p', 'üòõ']]\n",
    "_emoji_re = '[\\U00010000-\\U0010ffff]+'\n",
    "emoji_re = re.compile(_emoji_re, flags=re.UNICODE)\n",
    "\n",
    "def emoji_normalize(text):\n",
    "    for e1, e2 in EMOJIS:\n",
    "        text = text.replace(e1, e2)\n",
    "    return text\n",
    "\n",
    "def is_emoji(text):\n",
    "    emoji = \"\".join(re.findall(_emoji_re, text))\n",
    "    return emoji == text\n",
    "\n",
    "def emoji_isolate(text):\n",
    "    EMJ = \"__EMOJI__\"\n",
    "    emoji_list = re.findall(_emoji_re, text)\n",
    "    text = emoji_re.sub(f\" {EMJ} \", text)\n",
    "    new_str, ctr = [], 0\n",
    "    for tok in text.split():\n",
    "        if tok == EMJ:\n",
    "            new_str.append(emoji_list[ctr])\n",
    "            ctr += 1\n",
    "        else:\n",
    "            new_str.append(tok)\n",
    "    return \" \".join(new_str).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def ascii_normalize(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_re_escape = re.compile('[%s]' % re.escape('!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~'))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punct_re_escape.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = ascii_normalize(text)\n",
    "    text = emoji_normalize(text)\n",
    "    text = emoji_isolate(text) \n",
    "    text = remove_punctuation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_pred(query):\n",
    "    pred = nb_model.predict([query])[0]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.is_there_early_check_in'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pred(\"what time is early check-in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop Task #2: Further preprocessing steps\n",
    "Add other types of preprocessing relevant to the dataset you created. It could be from any of the ones listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_pred_top3(query):\n",
    "    tokenized_query = tokenize_nd_join(query)\n",
    "    pred_prob = nb_model.predict_proba([tokenized_query])\n",
    "    preds_sorted = np.argsort(pred_prob)\n",
    "    top3 = preds_sorted[:,-1],preds_sorted[:,-2],preds_sorted[:,-2]\n",
    "    if pred_prob[0,top3[0]] > (pred_prob[0,top3[1]] + pred_prob[0,top3[2]])*0.5:\n",
    "        pred = nb_model.named_steps['clf'].classes_[top3[0]][0]\n",
    "        return pred\n",
    "    return UNK\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.is_there_early_check_in'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pred_top3(\"is there early check-in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(query):\n",
    "    query = query.lower()\n",
    "    pred = exact_match(query)\n",
    "    if pred == UNK: pred = exact_match(preprocess(query))\n",
    "    if pred == UNK: pred = nb_pred_top3(query)\n",
    "    if pred == UNK: pred = nb_pred_top3(preprocess(query))\n",
    "    if pred == UNK: pred = fuzzy_matching(query)\n",
    "    if pred == UNK: pred = fuzzy_matching(preprocess(query))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.when_is_check_in'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"when is check-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.when_is_check_in'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"what time is check-in for my room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.is_there_late_check_out'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"I don't want to check-in late\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving ML to DL\n",
    "We see that this pipeline using some rules and a probabilistic model are working quite well.\n",
    "However, it doesn't scale with data and requires adding a lot of preprocessing and nuances to get working properly\n",
    "\n",
    "Pros:\n",
    "- There are noticeable improvement in using NNs over the current probabilistic model.\n",
    "- Model can scale with data i.e it can improve as we add more annotated training data\n",
    "- This can be a good point to move to NNs, since we are reaching the limits of rule based systems e.g fewer engineered features\n",
    "- Simplified pipeline\n",
    "\n",
    "Cons:\n",
    "- Huge gains cannot be seen until the data is cleaned. \n",
    "- In its current state, the model will either be the same or slightly better than the current approach.\n",
    "- Infrastructure changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Distil Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the sample dataset may be bit too small for this part of the workshop we will be using a public one\n",
    "from [here](https://www.kaggle.com/hassanamin/atis-airlinetravelinformationsystem/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/kumar-shridhar/Know-Your-Intent/master/datasets/NLU-Evaluation-Corpora/ChatbotCorpus.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_dump = json.load(open(\"./ChatbotCorpus.json\",'r'))\n",
    "x1 = [s['text'] for s in j_dump['sentences']]\n",
    "y1 = [s['intent'] for s in j_dump['sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to go marienplatz</td>\n",
       "      <td>FindConnection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when is the next train in muncher freiheit?</td>\n",
       "      <td>DepartureTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when does the next u-bahn leaves from garching...</td>\n",
       "      <td>DepartureTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from olympia einkaufszentrum to hauptbahnhof</td>\n",
       "      <td>FindConnection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when is the next train from winterstra√üe 12 to...</td>\n",
       "      <td>FindConnection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0                           i want to go marienplatz  FindConnection\n",
       "1        when is the next train in muncher freiheit?   DepartureTime\n",
       "2  when does the next u-bahn leaves from garching...   DepartureTime\n",
       "3       from olympia einkaufszentrum to hauptbahnhof  FindConnection\n",
       "4  when is the next train from winterstra√üe 12 to...  FindConnection"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.stack([x1, y1],1), columns=['text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>what flights are available from pittsburgh to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atis_flight_time</td>\n",
       "      <td>what is the arrival time in san francisco for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>cheapest airfare from tacoma to orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i need a flight tomorrow from columbus to min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label                                               text\n",
       "0       atis_flight   what flights are available from pittsburgh to...\n",
       "1  atis_flight_time   what is the arrival time in san francisco for...\n",
       "2      atis_airfare            cheapest airfare from tacoma to orlando\n",
       "3      atis_airfare   round trip fares from pittsburgh to philadelp...\n",
       "4       atis_flight   i need a flight tomorrow from columbus to min..."
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"284285_585165_bundle_archive/atis_intents.csv\",header=0,names=['label', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 4977)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['label'])), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting fastai code for training transformers was inspired from this [blog post](https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        tokens = [CLS] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "        \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, \n",
    "                                       include_bos=False, \n",
    "                                       include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pad_idx = transformer_tokenizer.pad_token_id\n",
    "\n",
    "databunch = (TextList.from_df(df, cols='text', processor=transformer_processor)\n",
    "             .split_by_rand_pct()\n",
    "             .label_from_df(cols= 'label')\n",
    "             .databunch(bs=64, pad_first=False, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "  \n",
    "    def __init__(self, transformer):\n",
    "        super(TransformerModel,self).__init__()\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # Return only the logits from the transfomer\n",
    "        logits = self.transformer(input_ids)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "config.num_labels = databunch.train_ds.c\n",
    "\n",
    "distil_bert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "transformer_model = TransformerModel(distil_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learn = Learner(databunch, transformer_model, opt_func = CustomAdamW, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer): DistilBertForSequenceClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 00:29<00:29]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.058806</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='28' class='' max='62', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      45.16% [28/62 00:16<00:19 4.0035]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10,max_lr=1e-2,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_transformer(query):\n",
    "    return learn.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = TextClassificationInterpretation(learn,*learn.get_preds(with_loss=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.show_top_losses(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(query):\n",
    "    query = query.lower()\n",
    "    pred = exact_match(query)\n",
    "    if pred == UNK: pred = exact_match(preprocess(query),bot)\n",
    "    if pred == UNK: pred = predict_transformer(query)\n",
    "    if pred == UNK: pred = predict_transformer(preprocess(query))\n",
    "    if pred == UNK: pred = fuzzy_matching(query)\n",
    "    if pred == UNK: pred = fuzzy_matching(preprocess(query))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop Task 3: Using Named Entity Recognition to extract parameters (10 min)\n",
    "Generalizing your training data with entity classes\n",
    "Add named entities to one intent and use spaCy to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterModel():\n",
    "    \n",
    "    def __init__(self, param_list):\n",
    "        self.parameters = param_list\n",
    "        self.label_ = 'PARAM'\n",
    "    \n",
    "    def replace_entities(self, text):\n",
    "        \"\"\"Replace entities in the text with their respective labels\"\"\"\n",
    "        for p in self.parameters:\n",
    "            if p in text:\n",
    "                entity_replaced_text = text.replace(p, f'<__{self.label_}__>')\n",
    "        return entity_replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list = ['japanese','indian','thai','chinese','fast food','bbq','cafe']\n",
    "food_param_model = ParameterModel(food_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want <__PARAM__>'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_param_model.replace_entities(\"I want fast food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'en_core_web_md'\n",
    "\n",
    "class SpacyModel(object):\n",
    "    spacy_model = None  # Where we keep the model when it's loaded\n",
    "\n",
    "    @classmethod\n",
    "    def get_base_spacy_model(cls):\n",
    "        \"\"\"Get the base spacy model\"\"\"\n",
    "        if not cls.spacy_model:\n",
    "            cls.spacy_model = spacy.load(MODEL_NAME)\n",
    "        return cls.spacy_model\n",
    "    \n",
    "    @classmethod\n",
    "    def replace_entities(cls, text):\n",
    "        \"\"\"Replace entities in the text with their respective labels\"\"\"\n",
    "        spacy_model = cls.get_base_spacy_model()\n",
    "        doc = spacy_model(text)\n",
    "        entity_replaced_text = text\n",
    "        for e in reversed(doc.ents):\n",
    "            start = e.start_char\n",
    "            end = start + len(e.text)\n",
    "            entity_replaced_text = entity_replaced_text[:start] + f'<__{e.label_}__>' + entity_replaced_text[end:]\n",
    "        return entity_replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how do i get to <__GPE__>'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpacyModel.replace_entities(\"how do i get to shibuya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can i get a reservation for <__DATE__>'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpacyModel.replace_entities(\"can i get a reservation for Sunday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop Task 4: Using users to disambiguate intents (10 min)\n",
    "When two intents are good candidates for the user's text, instead of picking the best, ask the user which they meant.\n",
    "Add disambiguation ability in your bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop Task 5: Typos (10 min)\n",
    "Since users are typing in their text, errors are common. Hence, the bot must be resilient to typos\n",
    "Add typo correction in your bot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
